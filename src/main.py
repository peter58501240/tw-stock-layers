from __future__ import annotations

# =============================
# Configï¼ˆåˆç‰ˆï¼šå…ˆè®“ä½ ã€Œçœ‹å¾—åˆ°æ±è¥¿ã€ï¼‰
# =============================
BACKFILL_DAYS = 30          # å¾€å‰è£œ 30 å¤©ï¼Œä¿è­‰ MA20 æˆå½¢ï¼ˆé‡åˆ°å‡æ—¥ä¹Ÿå¤ ï¼‰
E_DRAWDOWN = 0.08           # å¼·å‹¢è‚¡å›è½ -8% å…§ä»è¦–ç‚ºå¼·å‹¢ï¼ˆåˆç‰ˆç”¨ï¼‰
HISTORY_PATH = "outputs/history_prices.csv"
OUT_HTML = "docs/index.html"

TWSE_BASE = "https://openapi.twse.com.tw/v1"
TWSE_DAILY_ALL = f"{TWSE_BASE}/exchangeReport/STOCK_DAY_ALL"

# åˆç‰ˆï¼šåªåš MA5/10/20ï¼ˆä¸è¿½æ±‚ MA60/MA240ï¼Œå¦å‰‡è¦å¾ˆé•·æ­·å²ï¼‰
MA_WINDOWS = (5, 10, 20)

# =============================
# Imports
# =============================
import os
import datetime as dt
from dataclasses import dataclass
from typing import Optional, Tuple, Any, List

import numpy as np
import pandas as pd
import requests


# =============================
# Data Structures
# =============================
@dataclass
class FetchResult:
    df: pd.DataFrame
    source: str
    ok: bool
    error: Optional[str] = None
    warn: Optional[str] = None


# =============================
# Helpers
# =============================
def _http_get(url: str, timeout: int = 30) -> Tuple[int, str, str]:
    r = requests.get(url, timeout=timeout, headers={"User-Agent": "tw-stock-layers/1.0"})
    ct = r.headers.get("content-type", "")
    return r.status_code, ct, r.text


def _try_parse_json(text: str) -> Tuple[bool, Optional[Any], Optional[str]]:
    try:
        return True, requests.models.complexjson.loads(text), None
    except Exception as e:
        return False, None, f"{type(e).__name__}: {e}"


def normalize_twse(df: pd.DataFrame) -> pd.DataFrame:
    """
    TWSE STOCK_DAY_ALL å¸¸è¦‹æ¬„ä½ï¼š
    Date, code, name, volume, TradeValue, OpeningPrice, HighestPrice, LowestPrice, ClosingPrice, Change, Transaction
    æˆ‘å€‘åªéœ€è¦ code/name/close/volume
    """
    if df is None or df.empty:
        return df

    # æ¬„ä½æ˜ å°„
    col_map = {
        "Date": "date",
        "æ—¥æœŸ": "date",
        "code": "code",
        "è­‰åˆ¸ä»£è™Ÿ": "code",
        "name": "name",
        "è­‰åˆ¸åç¨±": "name",
        "volume": "volume",
        "æˆäº¤è‚¡æ•¸": "volume",
        "ClosingPrice": "close",
        "æ”¶ç›¤åƒ¹": "close",
        "æ”¶ç›¤": "close",
    }
    df = df.rename(columns={c: col_map.get(c, c) for c in df.columns})

    # æ¸…ç† code
    if "code" in df.columns:
        df["code"] = df["code"].astype(str).str.strip()

    # close/volume è½‰æ•¸å­—
    if "close" in df.columns:
        df["close"] = pd.to_numeric(df["close"], errors="coerce")
    if "volume" in df.columns:
        df["volume"] = pd.to_numeric(df["volume"], errors="coerce")

    df["market"] = "TWSE"
    return df


# =============================
# Fetch
# =============================
def fetch_twse_daily_all(for_date: Optional[pd.Timestamp] = None) -> FetchResult:
    """
    å–å¾— TWSE å…¨å¸‚å ´æ—¥è³‡æ–™ï¼ˆMVP å¯¬é¬†ç‰ˆï¼‰
    """
    try:
        url = TWSE_DAILY_ALL
        if for_date is not None:
            ymd = for_date.strftime("%Y%m%d")
            url = f"{TWSE_DAILY_ALL}?date={ymd}"

        status, ct, text = _http_get(url)
        if status != 200:
            return FetchResult(pd.DataFrame(), "TWSE", False, f"HTTP {status} from TWSE")

        ok, data, jerr = _try_parse_json(text)
        if not ok or data is None:
            return FetchResult(pd.DataFrame(), "TWSE", False, f"TWSE JSON parse failed: {jerr}")

        df = pd.DataFrame(data)
        df = normalize_twse(df)

 # MVPï¼šåªè¦ normalize å¾Œæœ‰è³‡æ–™å°±æ”¾è¡Œ
return FetchResult(df, "TWSE", True)
        return FetchResult(df, "TWSE", True)

    except Exception as e:
        return FetchResult(pd.DataFrame(), "TWSE", False, f"{type(e).__name__}: {e}")


# =============================
# History IO
# =============================
def load_history() -> pd.DataFrame:
    if os.path.exists(HISTORY_PATH):
        try:
            hist = pd.read_csv(HISTORY_PATH, dtype={"code": str})
            hist["date"] = pd.to_datetime(hist["date"])
            return hist
        except Exception:
            pass

    return pd.DataFrame(columns=["date", "code", "market", "name", "close", "volume"])


def append_day(history: pd.DataFrame, day_df: pd.DataFrame, day: pd.Timestamp) -> pd.DataFrame:
    keep = ["code", "market", "close"]
    if "name" in day_df.columns:
        keep.append("name")
    if "volume" in day_df.columns:
        keep.append("volume")

    df = day_df[keep].copy()
    df["date"] = day
    df["code"] = df["code"].astype(str).str.strip()

    out = pd.concat([history, df], ignore_index=True)
    out["date"] = pd.to_datetime(out["date"])
    out = out.drop_duplicates(subset=["date", "code", "market"], keep="last")
    return out


def backfill_twse_recent_days(history: pd.DataFrame, today: pd.Timestamp, target_days: int) -> Tuple[pd.DataFrame, int]:
    """
    å¾€å‰è£œ target_days å€‹ã€Œå¯èƒ½çš„äº¤æ˜“æ—¥ã€ã€‚
    é€™è£¡ç”¨æ—¥æ›†å¾€å‰æƒï¼ˆå«å‡æ—¥ï¼‰ï¼ŒæŠ“ä¸åˆ°å°±è·³éï¼›ç›´åˆ°è£œåˆ° target_days æ¬¡æˆåŠŸç‚ºæ­¢ã€‚
    """
    if target_days <= 0:
        return history, 0

    # å·²æœ‰çš„æ—¥æœŸé›†åˆï¼ˆTWSEï¼‰
    have_dates = set()
    if not history.empty:
        h = history[history["market"] == "TWSE"].copy()
        if not h.empty:
            have_dates = set(pd.to_datetime(h["date"]).dt.date.astype(str).tolist())

    filled = 0
    # å¾€å‰æƒ target_days * 2ï¼Œå‡æ—¥å¤šä¹Ÿå¤ 
    for i in range(1, target_days * 3 + 1):
        d = today - pd.Timedelta(days=i)
        d_key = d.date().isoformat()
        if d_key in have_dates:
            continue

        r = fetch_twse_daily_all(d)
        if not r.ok or r.df.empty:
            continue

        history = append_day(history, r.df, d)
        have_dates.add(d_key)
        filled += 1
        if filled >= target_days:
            break

    return history, filled


# =============================
# Indicatorsï¼ˆåˆç‰ˆï¼šMA5/10/20 + å›è½ï¼‰
# =============================
def compute_indicators(hist: pd.DataFrame) -> pd.DataFrame:
    hist = hist.sort_values(["market", "code", "date"]).copy()
    hist["close"] = pd.to_numeric(hist["close"], errors="coerce")
    hist["volume"] = pd.to_numeric(hist.get("volume", np.nan), errors="coerce")

    def _grp(g: pd.DataFrame) -> pd.DataFrame:
        g = g.copy()
        g["ma5"] = g["close"].rolling(5).mean()
        g["ma10"] = g["close"].rolling(10).mean()
        g["ma20"] = g["close"].rolling(20).mean()
        g["hi_close"] = g["close"].cummax()
        g["dd_from_hi"] = g["close"] / g["hi_close"] - 1.0
        return g

    return hist.groupby(["market", "code"], group_keys=False).apply(_grp)


# =============================
# Layer Logicï¼ˆåˆç‰ˆï¼šä¿è­‰åˆ†å±¤æœ‰æ±è¥¿ï¼‰
# =============================
def layer_logic(today_row: pd.Series) -> Tuple[str, str]:
    """
    åˆç‰ˆåˆ†å±¤ï¼ˆåªç”¨ MA5/10/20ï¼‰ï¼š
    - Eï¼šclose > MA5/10/20 ä¸” dd > -8%
    - Bï¼šMA5 > MA10 > MA20ï¼ˆå¤šé ­æ’åˆ—ï¼‰
    - Cï¼šclose > MA20ï¼ˆæ•´ç†ï¼‰
    - Dï¼šclose <= MA20ï¼ˆè½‰å¼±ï¼‰
    - Zï¼šclose æˆ– MA20 ç¼º
    """
    close = pd.to_numeric(today_row.get("close"), errors="coerce")
    if pd.isna(close):
        return "Z", "è³‡æ–™ä¸è¶³ï¼šclose ç¼º"

    ma5 = pd.to_numeric(today_row.get("ma5"), errors="coerce")
    ma10 = pd.to_numeric(today_row.get("ma10"), errors="coerce")
    ma20 = pd.to_numeric(today_row.get("ma20"), errors="coerce")

    if pd.isna(ma20):
        return "Z", "è³‡æ–™ä¸è¶³ï¼šMA20 æœªæˆå½¢ï¼ˆåˆç‰ˆï¼‰"

    dd = pd.to_numeric(today_row.get("dd_from_hi"), errors="coerce")
    if pd.isna(dd):
        dd = 0.0

    if (not pd.isna(ma5)) and (not pd.isna(ma10)) and close > ma5 and close > ma10 and close > ma20 and dd > -E_DRAWDOWN:
        return "E", "å¼·å‹¢ï¼šæ”¶ç›¤>MA5/10/20 ä¸”æœªå›è½-8%ï¼ˆåˆç‰ˆï¼‰"

    if (not pd.isna(ma5)) and (not pd.isna(ma10)) and ma5 > ma10 > ma20:
        return "B", "è¶¨å‹¢ï¼šMA5>MA10>MA20ï¼ˆåˆç‰ˆï¼‰"

    if close > ma20:
        return "C", "æ•´ç†ï¼šæ”¶ç›¤>MA20ï¼ˆåˆç‰ˆï¼‰"

    return "D", "è½‰å¼±ï¼šæ”¶ç›¤â‰¤MA20ï¼ˆåˆç‰ˆï¼‰"


# =============================
# Report HTMLï¼ˆæ‘˜è¦è­¦ç¤ºï¼‰
# =============================
def build_html_report(date_str: str, layers: pd.DataFrame, warnings: List[str], errors: List[str]) -> str:
    def _table(df: pd.DataFrame, title: str) -> str:
        if df.empty:
            return f"<h2>{title}</h2><p>(ç©º)</p>"
        cols = ["market", "code", "name", "close", "layer", "reason"]
        df2 = df.copy()
        for c in cols:
            if c not in df2.columns:
                df2[c] = ""
        df2 = df2[cols]
        return f"<h2>{title}</h2>" + df2.to_html(index=False, escape=True)

    html = []
    html.append("<!doctype html><html><head><meta charset='utf-8'>")
    html.append("<meta name='viewport' content='width=device-width, initial-scale=1'>")
    html.append("<title>TW Stock Layers - Daily</title>")
    html.append(
        "<style>"
        "body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial; margin:24px;}"
        "table{border-collapse:collapse; width:100%;}"
        "th,td{border:1px solid #ddd; padding:8px;}"
        "th{background:#f5f5f5;}"
        ".pill{display:inline-block;padding:2px 8px;border-radius:999px;background:#f2f2f2;margin-right:8px;}"
        "</style>"
    )
    html.append("</head><body>")
    html.append(f"<h1>æ¯æ—¥åˆ†å±¤å ±è¡¨</h1><p>æ—¥æœŸï¼š{date_str}ï¼ˆAsia/Taipeiï¼‰</p>")

    if errors:
        html.append("<h2>æŠ“å–éŒ¯èª¤</h2><ul>")
        for e in errors:
            html.append(f"<li>{e}</li>")
        html.append("</ul>")

    # æ‘˜è¦è­¦ç¤ºï¼ˆä¸è¦æ»¿ç‰ˆï¼‰
    if warnings:
        html.append("<h2>å³æ™‚è­¦ç¤ºï¼ˆæ‘˜è¦ï½œMVPï¼‰</h2><ul>")
        for w in warnings[:8]:
            html.append(f"<li>{w}</li>")
        if len(warnings) > 8:
            html.append(f"<li>â€¦å¦æœ‰ {len(warnings)-8} å‰‡æç¤ºçœç•¥</li>")
        html.append("</ul>")

    # åˆ†å±¤
    for layer in ["E", "B", "C", "D", "Z"]:
        df_layer = layers[layers["layer"] == layer].sort_values(["market", "code"])
        html.append(_table(df_layer, f"{layer} å±¤"))

    html.append("<hr>")
    html.append("<p style='color:#666'>è¨»ï¼šåˆç‰ˆå…ˆä»¥ TWSE + MA5/10/20 è®“åˆ†å±¤ã€Œå¯ç”¨å¯çœ‹ã€ã€‚å¾ŒçºŒå†é€æ­¥åŠ å…¥ TPExã€MA60/240ã€RSã€ç‡Ÿæ”¶èˆ‡è¦å‰‡å…¨æ–‡ã€‚</p>")
    html.append("</body></html>")
    return "\n".join(html)


# =============================
# Main
# =============================
def main() -> int:
    os.makedirs("docs", exist_ok=True)
    os.makedirs("outputs", exist_ok=True)

    today = pd.Timestamp(dt.datetime.now().date())
    date_str = today.strftime("%Y-%m-%d")

    errors: List[str] = []
    warnings: List[str] = []

    # 1) å– TWSE ä»Šæ—¥è³‡æ–™
    twse = fetch_twse_daily_all(None)
    if not twse.ok or twse.df.empty:
        errors.append(f"TWSE å–å¾—å¤±æ•—ï¼š{twse.error}")
        # ä»è¼¸å‡ºç©ºå ±è¡¨é¿å… Pages ç©ºç™½
        empty = pd.DataFrame(columns=["market", "code", "name", "close", "layer", "reason"])
        html = build_html_report(date_str, empty, warnings, errors)
        with open(OUT_HTML, "w", encoding="utf-8") as f:
            f.write(html)
        return 0

    warnings.append("ğŸŸ¢ MVPï¼šç›®å‰åªè·‘ TWSEï¼ˆTPEx æš«åœï¼‰")

    # 2) è¼‰å…¥æ­·å²
    hist = load_history()

    # 3) å›è£œæ­·å²ï¼ˆåŠ é€Ÿ MA20 æˆå½¢ï¼‰
    hist, filled = backfill_twse_recent_days(hist, today, BACKFILL_DAYS)
    warnings.append(f"ğŸŸ¢ TWSE å›è£œï¼šæˆåŠŸè£œåˆ° {filled} å¤©ï¼ˆç›®æ¨™ {BACKFILL_DAYS}ï¼‰")

    # 4) å¯«å…¥ä»Šæ—¥
    hist = append_day(hist, twse.df, today)
    hist.to_csv(HISTORY_PATH, index=False, encoding="utf-8")

    # 5) ç®—æŒ‡æ¨™
    hist_ind = compute_indicators(hist)

    # 6) å–ä»Šæ—¥åˆ‡ç‰‡
    today_ind = hist_ind[hist_ind["date"] == today].copy()
    if today_ind.empty:
        errors.append("ä»Šæ—¥æŒ‡æ¨™è³‡æ–™ç‚ºç©ºï¼ˆå¯èƒ½æ—¥æœŸå¯«å…¥å¤±æ•—ï¼‰")
        empty = pd.DataFrame(columns=["market", "code", "name", "close", "layer", "reason"])
        html = build_html_report(date_str, empty, warnings, errors)
        with open(OUT_HTML, "w", encoding="utf-8") as f:
            f.write(html)
        return 0

    # 7) åˆ†å±¤
    out_rows = []
    for _, row in today_ind.iterrows():
        layer, reason = layer_logic(row)
        out_rows.append({
            "market": row.get("market", ""),
            "code": str(row.get("code", "")).strip(),
            "name": row.get("name", ""),
            "close": row.get("close", ""),
            "layer": layer,
            "reason": reason,
        })
    layers = pd.DataFrame(out_rows)

    # 8) æ‘˜è¦çµ±è¨ˆï¼ˆè®“ä½ çˆ½ï¼šä¸€çœ¼çœ‹åˆ°æœ‰æ²’æœ‰åˆ†å±¤ï¼‰
    cnt = layers["layer"].value_counts().to_dict()
    warnings.append("ğŸ“Š åˆ†ä½ˆï¼š" + " / ".join([f"{k}:{v}" for k, v in cnt.items()]))

    # 9) è¼¸å‡º HTML
    html = build_html_report(date_str, layers, warnings, errors)
    with open(OUT_HTML, "w", encoding="utf-8") as f:
        f.write(html)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
