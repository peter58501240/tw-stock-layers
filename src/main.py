from __future__ import annotations

import os
import sys
import json
import math
import datetime as dt
from dataclasses import dataclass
from typing import Optional, Tuple

import numpy as np
import pandas as pd
import requests


# -----------------------------
# Config (å¯èª¿æ•´/æ›¿æ›è³‡æ–™æº)
# -----------------------------
TWSE_BASE = "https://openapi.twse.com.tw/v1"
TPEX_BASE = "https://www.tpex.org.tw/openapi/v1"  # è‹¥å¯¦éš› base ä¸åŒï¼Œä¹‹å¾Œä»¥å›å‚³éŒ¯èª¤èª¿æ•´

# å˜—è©¦æŠ“ã€Œç•¶æ—¥å…¨å¸‚å ´è¡Œæƒ…ã€çš„ç«¯é»ï¼ˆè‹¥ç«¯é»ä¸åŒï¼Œå…ˆè®“ç¨‹å¼è¼¸å‡ºéŒ¯èª¤ï¼Œä¾¿æ–¼æˆ‘å¿«é€Ÿä¿®æ­£ï¼‰
TWSE_DAILY_ALL = f"{TWSE_BASE}/exchangeReport/STOCK_DAY_ALL"
TPEX_DAILY_ALL_CANDIDATES = [
    f"{TPEX_BASE}/tpex_mainboard_daily",   # å€™é¸1ï¼ˆå¯èƒ½éœ€èª¿æ•´ï¼‰
    f"{TPEX_BASE}/stock_aftertrading_daily_trading_info",  # å€™é¸2ï¼ˆå¯èƒ½éœ€èª¿æ•´ï¼‰
]

HISTORY_PATH = "outputs/history_prices.csv"
OUT_HTML = "docs/index.html"


# -----------------------------
# v7.9.9.1 æ ¸å¿ƒåƒæ•¸ï¼ˆMVP å­é›†ï¼‰
# -----------------------------
SDR_DAYS = 30
SDR_MIN_RETURN = 0.05  # +5%
E_STOP_MA = 20
E_DRAWDOWN = 0.08      # -8%
CYCLE_DRAWDOWN = 0.12  # -12%
GLOBAL_STOP = 0.12     # -12%
CYCLE_MA = 240

# ç•¶è³‡æ–™ä¸è¶³æ™‚ä¾ Â§11ï¼šä¸å¯æ”¾å¯¬ â†’ é€² Z
MIN_HISTORY_FOR_MA240 = 240
MIN_HISTORY_FOR_MA60 = 60
MIN_HISTORY_FOR_MA20 = 20


@dataclass
class FetchResult:
    df: pd.DataFrame
    source: str
    ok: bool
    error: Optional[str] = None


def _http_get_json(url: str, timeout: int = 30) -> Tuple[bool, Optional[object], Optional[str]]:
    try:
        r = requests.get(url, timeout=timeout, headers={"User-Agent": "tw-stock-layers/1.0"})
        if r.status_code != 200:
            return False, None, f"HTTP {r.status_code}: {url}"
        # æœ‰äº›ç«¯é»å› JSONï¼Œæœ‰äº›å› text/jsonï¼›çµ±ä¸€å˜—è©¦ json()
        return True, r.json(), None
    except Exception as e:
        return False, None, f"{type(e).__name__}: {e}"


def fetch_twse_daily_all() -> FetchResult:
    ok, data, err = _http_get_json(TWSE_DAILY_ALL)
    if not ok:
        return FetchResult(pd.DataFrame(), "TWSE", False, err)

    # å˜—è©¦è‡ªå‹•è¾¨è­˜æ¬„ä½ï¼ˆä¸åŒç«¯é»å¯èƒ½æ¬„åä¸åŒï¼‰
    df = pd.DataFrame(data)
    if df.empty:
        return FetchResult(df, "TWSE", False, "TWSE returned empty dataset")

    # å¸¸è¦‹æ¬„ä½çŒœæ¸¬ï¼šCode/StockNo/è­‰åˆ¸ä»£è™Ÿ, Name/è­‰åˆ¸åç¨±, Close/æ”¶ç›¤åƒ¹, Volume/æˆäº¤è‚¡æ•¸
    colmap = {}
    for c in df.columns:
        lc = str(c).lower()
        if "code" in lc or "stockno" in lc or "è­‰åˆ¸ä»£è™Ÿ" in c:
            colmap[c] = "code"
        elif "name" in lc or "è­‰åˆ¸åç¨±" in c:
            colmap[c] = "name"
        elif "close" in lc or "æ”¶ç›¤" in c:
            colmap[c] = "close"
        elif "volume" in lc or "æˆäº¤è‚¡æ•¸" in c or "æˆäº¤é‡" in c:
            colmap[c] = "volume"

    df = df.rename(columns=colmap)
    need = {"code", "close"}
    if not need.issubset(df.columns):
        return FetchResult(df, "TWSE", False, f"TWSE schema unexpected: columns={list(df.columns)[:30]}")

    df["market"] = "TWSE"
    return FetchResult(df, "TWSE", True)


def fetch_tpex_daily_all() -> FetchResult:
    last_err = None
    for url in TPEX_DAILY_ALL_CANDIDATES:
        ok, data, err = _http_get_json(url)
        if not ok:
            last_err = err
            continue
        df = pd.DataFrame(data)
        if df.empty:
            last_err = f"TPEX empty dataset: {url}"
            continue

        colmap = {}
        for c in df.columns:
            lc = str(c).lower()
            if "code" in lc or "stock" in lc or "ä»£è™Ÿ" in c:
                colmap[c] = "code"
            elif "name" in lc or "åç¨±" in c:
                colmap[c] = "name"
            elif "close" in lc or "æ”¶ç›¤" in c:
                colmap[c] = "close"
            elif "volume" in lc or "æˆäº¤" in c:
                colmap[c] = "volume"

        df = df.rename(columns=colmap)
        if {"code", "close"}.issubset(df.columns):
            df["market"] = "TPEx"
            return FetchResult(df, "TPEx", True)

        last_err = f"TPEX schema unexpected: {url}, columns={list(df.columns)[:30]}"

    return FetchResult(pd.DataFrame(), "TPEx", False, last_err or "TPEX fetch failed")


def load_history() -> pd.DataFrame:
    if os.path.exists(HISTORY_PATH):
        try:
            hist = pd.read_csv(HISTORY_PATH, dtype={"code": str})
            hist["date"] = pd.to_datetime(hist["date"])
            return hist
        except Exception:
            pass
    return pd.DataFrame(columns=["date", "code", "market", "close", "volume"])


def append_today(history: pd.DataFrame, today_df: pd.DataFrame, today: pd.Timestamp) -> pd.DataFrame:
    # ä¿ç•™å¿…è¦æ¬„ä½
    keep = ["code", "market", "close"]
    if "volume" in today_df.columns:
        keep.append("volume")
    df = today_df[keep].copy()
    df["date"] = today
    df["code"] = df["code"].astype(str).str.strip()

    # å»é‡ï¼ˆåŒæ—¥åŒè‚¡åªç•™æœ€å¾Œï¼‰
    out = pd.concat([history, df], ignore_index=True)
    out["date"] = pd.to_datetime(out["date"])
    out = out.drop_duplicates(subset=["date", "code", "market"], keep="last")
    return out


def compute_indicators(hist: pd.DataFrame) -> pd.DataFrame:
    # ä»¥ (code, market) åˆ†çµ„è¨ˆç®— MA èˆ‡å›è½
    hist = hist.sort_values(["market", "code", "date"]).copy()
    hist["close"] = pd.to_numeric(hist["close"], errors="coerce")
    hist["volume"] = pd.to_numeric(hist.get("volume", np.nan), errors="coerce")

    def _grp(g: pd.DataFrame) -> pd.DataFrame:
        g = g.copy()
        g["ma20"] = g["close"].rolling(MIN_HISTORY_FOR_MA20).mean()
        g["ma60"] = g["close"].rolling(MIN_HISTORY_FOR_MA60).mean()
        g["ma240"] = g["close"].rolling(MIN_HISTORY_FOR_MA240).mean()
        g["hi_close"] = g["close"].cummax()
        g["dd_from_hi"] = g["close"] / g["hi_close"] - 1.0
        return g

    return hist.groupby(["market", "code"], group_keys=False).apply(_grp)


def layer_logic(today_row: pd.Series, hist_tail: pd.DataFrame) -> Tuple[str, str]:
    """
    MVP åˆ†å±¤ï¼š
    - è³‡æ–™ä¸è¶³ï¼šZï¼ˆä¾ Â§11ï¼‰
    - Eï¼šä»Šæ—¥æ”¶ç›¤ > ma60 ä¸” dd_from_hi > -8% ä¸” close > ma20ï¼ˆè¿‘ä¼¼å¼·å‹¢çŸ­é©—è­‰ï¼‰
    - A/B/C/Dï¼šå…ˆç”¨ ma240/ma60 ä½œç²—åˆ†ï¼ˆå¾ŒçºŒå†æŠŠç‡Ÿæ”¶YoYã€RSã€é‡èƒ½ç­‰è£œé½Šï¼‰
    - å¾ªç’°è‚¡/é‡‘èè‚¡åˆ¤å®šï¼šMVP æš«ä¸è‡ªå‹•è¾¨è­˜ï¼ˆå…ˆç•™å¾…ä¸‹ä¸€æ­¥åŠ ç”¢æ¥­åˆ†é¡ï¼‰
    """
    # è³‡æ–™ä¸è¶³ â†’ Z
    if pd.isna(today_row.get("ma60")) or pd.isna(today_row.get("ma240")) or pd.isna(today_row.get("ma20")):
        return "Z", "Â§11 è³‡æ–™ä¸è¶³ï¼šMA ä¸è¶³ï¼Œåˆ—è§€å¯Ÿ"

    close = float(today_row["close"])
    ma20 = float(today_row["ma20"])
    ma60 = float(today_row["ma60"])
    ma240 = float(today_row["ma240"])
    dd = float(today_row.get("dd_from_hi", 0.0))

    # è¿‘ä¼¼ Eï¼ˆå¼·å‹•èƒ½çŸ­é©—è­‰ï¼‰ï¼šç«™ä¸Š ma60ã€ç«™ä¸Š ma20ã€æœªå›è½ -8%
    if close > ma60 and close > ma20 and dd > -E_DRAWDOWN:
        return "E", "è¿‘ä¼¼Eï¼šæ”¶ç›¤>MA60ä¸”>MA20ä¸”æœªå›è½-8%"

    # è¶¨å‹¢ç²—åˆ†
    if close > ma240 and close > ma60:
        return "B", "è¶¨å‹¢ï¼šæ”¶ç›¤>MA240ä¸”>MA60ï¼ˆMVPï¼‰"
    if close > ma240 and close <= ma60:
        return "C", "å›æª”ï¼šæ”¶ç›¤>MA240ä½†â‰¤MA60ï¼ˆMVPï¼‰"
    if close <= ma240 and close > ma60:
        return "D", "åå½ˆï¼šæ”¶ç›¤â‰¤MA240ä½†>MA60ï¼ˆMVPï¼‰"

    return "Z", "å¼±å‹¢ï¼šæœªé”è¶¨å‹¢æ¢ä»¶ï¼Œåˆ—è§€å¯Ÿï¼ˆMVPï¼‰"


def build_html_report(date_str: str, layers: pd.DataFrame, warnings: list[str], errors: list[str]) -> str:
    def _table(df: pd.DataFrame, title: str) -> str:
        if df.empty:
            return f"<h2>{title}</h2><p>(ç©º)</p>"
        cols = ["market", "code", "name", "close", "layer", "reason"]
        df2 = df.copy()
        for c in cols:
            if c not in df2.columns:
                df2[c] = ""
        df2 = df2[cols]
        return f"<h2>{title}</h2>" + df2.to_html(index=False, escape=True)

    html = []
    html.append("<!doctype html><html><head><meta charset='utf-8'>")
    html.append("<meta name='viewport' content='width=device-width, initial-scale=1'>")
    html.append("<title>TW Stock Layers - Daily</title>")
    html.append("<style>body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial; margin:24px;} table{border-collapse:collapse; width:100%;} th,td{border:1px solid #ddd; padding:8px;} th{background:#f5f5f5;}</style>")
    html.append("</head><body>")
    html.append(f"<h1>æ¯æ—¥åˆ†å±¤å ±è¡¨</h1><p>æ—¥æœŸï¼š{date_str}ï¼ˆAsia/Taipeiï¼‰</p>")

    if errors:
        html.append("<h2>æŠ“å–éŒ¯èª¤</h2><ul>")
        for e in errors:
            html.append(f"<li>{e}</li>")
        html.append("</ul>")

    if warnings:
        html.append("<h2>å³æ™‚è­¦ç¤ºï¼ˆMVPï¼‰</h2><ul>")
        for w in warnings:
            html.append(f"<li>{w}</li>")
        html.append("</ul>")

    # åˆ†å±¤è¼¸å‡º
    for layer in ["A", "B", "C", "D", "E", "Z"]:
        df_layer = layers[layers["layer"] == layer].sort_values(["market", "code"])
        html.append(_table(df_layer, f"{layer} å±¤"))

    html.append("<hr><p style='color:#666'>è¨»ï¼šæœ¬ç‰ˆæœ¬ç‚ºå¯ä¸Šç·š MVPã€‚ç•¶æ­·å²è³‡æ–™ç´¯ç©é” MA/é‡èƒ½/åŸºæœ¬é¢éœ€æ±‚å¾Œï¼Œåˆ†å±¤å°‡é€æ­¥ç¬¦åˆ v7.9.9.1 å…¨æ¢æ–‡ã€‚</p>")
    html.append("</body></html>")
    return "\n".join(html)


def main() -> int:
    os.makedirs("docs", exist_ok=True)
    os.makedirs("outputs", exist_ok=True)

    today = pd.Timestamp(dt.datetime.now().date())
    date_str = today.strftime("%Y-%m-%d")

    errors: list[str] = []
    warnings: list[str] = []

    twse = fetch_twse_daily_all()
    if not twse.ok:
        errors.append(f"TWSE å–å¾—å¤±æ•—ï¼š{twse.error}")
    tpex = fetch_tpex_daily_all()
    if not tpex.ok:
        errors.append(f"TPEx å–å¾—å¤±æ•—ï¼š{tpex.error}")

    daily = pd.concat([twse.df, tpex.df], ignore_index=True) if (twse.ok or tpex.ok) else pd.DataFrame()
    if daily.empty:
        html = build_html_report(date_str, pd.DataFrame(columns=["market","code","name","close","layer","reason"]), warnings, errors)
        with open(OUT_HTML, "w", encoding="utf-8") as f:
            f.write(html)
        return 0

    # è®€å–/ç´¯ç©æ­·å²
    hist = load_history()
    hist = append_today(hist, daily, today)
    hist.to_csv(HISTORY_PATH, index=False, encoding="utf-8")

    # è¨ˆç®—æŒ‡æ¨™
    hist_ind = compute_indicators(hist)
    # å–ä»Šæ—¥è³‡æ–™ï¼ˆå«æŒ‡æ¨™ï¼‰
    today_ind = hist_ind[hist_ind["date"] == today].copy()
    if today_ind.empty:
        errors.append("ä»Šæ—¥æŒ‡æ¨™è³‡æ–™ç‚ºç©ºï¼ˆå¯èƒ½æ˜¯æ—¥æœŸæ ¼å¼æˆ–å¯«å…¥å¤±æ•—ï¼‰")

    # åˆ†å±¤
    out_rows = []
    for _, row in today_ind.iterrows():
        layer, reason = layer_logic(row, hist_ind)
        out_rows.append({
            "market": row.get("market", ""),
            "code": str(row.get("code", "")).strip(),
            "name": row.get("name", ""),
            "close": row.get("close", ""),
            "layer": layer,
            "reason": reason,
        })
    layers = pd.DataFrame(out_rows)

    # MVP è­¦ç¤ºï¼ˆå…ˆåšå·¥ç¨‹ç´šï¼‰
    if any("å–å¾—å¤±æ•—" in e for e in errors):
        warnings.append("ğŸŸ  è³‡æ–™æºéƒ¨åˆ†å¤±æ•ˆï¼šä¾ Â§11 é™ç´šï¼Œä»Šæ—¥åˆ†å±¤å¯èƒ½åå‘ Z")
    z_ratio = (layers["layer"] == "Z").mean() if len(layers) else 1.0
    if z_ratio > 0.8:
        warnings.append("ğŸŸ¡ Z å±¤å æ¯”åé«˜ï¼šæ­·å²è³‡æ–™å°šåœ¨ç´¯ç©ï¼ˆå±¬æ­£å¸¸MVPéšæ®µï¼‰")

    # ç”¢å‡º HTML
    html = build_html_report(date_str, layers, warnings, errors)
    with open(OUT_HTML, "w", encoding="utf-8") as f:
        f.write(html)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
