from __future__ import annotations

import os
import sys
import json
import datetime as dt
from dataclasses import dataclass
from typing import Optional, Tuple, Any, List

import numpy as np
import pandas as pd
import requests

# =========================================
# Configï¼ˆä½ åªéœ€è¦æ”¹é€™è£¡ï¼‰
# =========================================
BACKFILL_DAYS = 20  # å¾€å‰è£œ N å€‹äº¤æ˜“æ—¥ï¼ˆå»ºè­° 20ï¼šMA20 æ‰æœƒå¿«æˆç«‹ï¼‰
TZ = "Asia/Taipei"

# åªåš TWSEï¼ˆTPEx å…ˆä¸è™•ç†ï¼Œè®“ä½ å…ˆçœ‹åˆ°è³‡æ–™ï¼‰
TWSE_BASE = "https://openapi.twse.com.tw/v1"
TWSE_DAILY_ALL = f"{TWSE_BASE}/exchangeReport/STOCK_DAY_ALL"

OUTPUTS_DIR = "outputs"
DOCS_DIR = "docs"
HISTORY_CSV = os.path.join(OUTPUTS_DIR, "history_prices.csv")
HTML_PATH_OUTPUTS = os.path.join(OUTPUTS_DIR, "index.html")
HTML_PATH_DOCS = os.path.join(DOCS_DIR, "index.html")


# =========================================
# Data Structures
# =========================================
@dataclass
class FetchResult:
    df: pd.DataFrame
    source: str
    ok: bool
    error: Optional[str] = None


# =========================================
# Helpers
# =========================================
def _now_taipei_date() -> dt.date:
    # GitHub runner ç”¨ UTCï¼Œé€™è£¡ç²—ç•¥ç”¨ UTC+8 æ›ç®—
    now_utc = dt.datetime.utcnow()
    now_tw = now_utc + dt.timedelta(hours=8)
    return now_tw.date()


def _is_weekend(d: dt.date) -> bool:
    return d.weekday() >= 5  # 5=Sat, 6=Sun


def _iter_prev_days(start: dt.date, n: int) -> List[dt.date]:
    """å›å‚³å¾ start å¾€å‰æ•¸ n å€‹ã€Œæ—¥æ›†æ—¥ã€ï¼Œä¸¦åœ¨ fetch æ™‚è·³éé€±æœ«ï¼ˆäº¤æ˜“æ‰€ä¼‘å¸‚ä¹Ÿæœƒè¢« fetch å¤±æ•—ç•¥éï¼‰ã€‚"""
    out = []
    cur = start
    while len(out) < n:
        cur = cur - dt.timedelta(days=1)
        out.append(cur)
    return out


def _http_get(url: str, timeout: int = 30) -> Tuple[int, str, str]:
    headers = {
        "User-Agent": "Mozilla/5.0 (GitHub Actions; tw-stock-layers)",
        "Accept": "application/json,text/plain,*/*",
    }
    r = requests.get(url, headers=headers, timeout=timeout)
    return r.status_code, r.headers.get("content-type", ""), r.text


def _try_parse_json(text: str) -> Tuple[bool, Any, Optional[str]]:
    try:
        return True, json.loads(text), None
    except Exception as e:
        return False, None, f"{type(e).__name__}: {e}"


def _pick_first_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    # ä¹Ÿåšå¤§å°å¯«å¯¬é¬†åŒ¹é…
    lower_map = {str(c).lower(): c for c in df.columns}
    for c in candidates:
        lc = c.lower()
        if lc in lower_map:
            return lower_map[lc]
    return None


def _to_float_series(s: pd.Series) -> pd.Series:
    # æŠŠå¯èƒ½å«é€—è™Ÿã€ç©ºç™½çš„å­—ä¸²è½‰æˆ float
    s2 = s.astype(str).str.replace(",", "", regex=False).str.strip()
    s2 = s2.replace({"--": np.nan, "nan": np.nan, "None": np.nan, "": np.nan})
    return pd.to_numeric(s2, errors="coerce")


def normalize_twse(raw: pd.DataFrame) -> pd.DataFrame:
    """
    æŠŠ TWSE STOCK_DAY_ALL å›å‚³æ¬„ä½çµ±ä¸€ç‚ºï¼š
      - code (str)
      - name (str)
      - close (float)
      - volume (float)  # å–®ä½ä¸å¼·æ±‚ï¼Œå…ˆç”¨ä¾†åšé‡èƒ½/ç•™æ¬„
      - market = "TWSE"
    """
    df = raw.copy()

    # å¸¸è¦‹æ¬„ä½åç¨±ï¼ˆTWSE openapi æœ‰æ™‚å¤§å°å¯«ä¸åŒï¼‰
    # ä¿®æ­£ï¼šå¢åŠ æ›´å¤šå¯èƒ½çš„æ¬„ä½åç¨±ï¼ŒåŒ…æ‹¬å¤§å°å¯«è®Šé«”
    code_col = _pick_first_col(df, ["Code", "code", "è­‰åˆ¸ä»£è™Ÿ", "è‚¡ç¥¨ä»£è™Ÿ", "StockCode"])
    name_col = _pick_first_col(df, ["Name", "name", "è­‰åˆ¸åç¨±", "è‚¡ç¥¨åç¨±", "CompanyName"])
    
    # é—œéµä¿®æ­£ï¼šæ”¶ç›¤åƒ¹å¯èƒ½æœ‰å¤šç¨®åç¨±
    close_col = _pick_first_col(df, [
        "ClosingPrice", "close", "Close", "æ”¶ç›¤åƒ¹", "æ”¶ç›¤", 
        "ClosingPrice", "Closing_Price", "price"
    ])
    
    vol_col = _pick_first_col(df, [
        "TradeVolume", "volume", "Volume", "æˆäº¤è‚¡æ•¸", "æˆäº¤é‡", 
        "TradingVolume", "Trading_Volume"
    ])

    # é™¤éŒ¯ï¼šå°å‡ºæ‰¾åˆ°çš„æ¬„ä½
    print(f"[DEBUG] Found columns: code={code_col}, name={name_col}, close={close_col}, vol={vol_col}")
    print(f"[DEBUG] Available columns: {list(df.columns)[:15]}")

    # å¿…è¦æ¬„ä½ï¼šcode / closeï¼ˆæ²’æœ‰å°±å›å‚³ç©ºï¼Œè®“ä¸Šå±¤åˆ¤å®š failï¼‰
    if code_col is None or close_col is None:
        print(f"[ERROR] Missing required columns! code_col={code_col}, close_col={close_col}")
        # ç›´æ¥å›å‚³åŸ dfï¼Œè®“ caller åšéŒ¯èª¤è¨Šæ¯
        return df

    out = pd.DataFrame()
    out["code"] = df[code_col].astype(str).str.strip()
    if name_col is not None:
        out["name"] = df[name_col].astype(str).str.strip()
    else:
        out["name"] = ""

    out["close"] = _to_float_series(df[close_col])

    if vol_col is not None:
        out["volume"] = _to_float_series(df[vol_col])
    else:
        out["volume"] = np.nan

    out["market"] = "TWSE"

    # å»æ‰ code ç©ºå€¼èˆ‡ close ç©ºå€¼
    out = out[(out["code"] != "") & (out["code"].notna())]
    out = out[out["close"].notna()]
    
    print(f"[DEBUG] Normalized {len(out)} stocks")

    return out.reset_index(drop=True)


# =========================================
# Fetch
# =========================================
def fetch_twse_daily_all(for_date: Optional[pd.Timestamp] = None) -> FetchResult:
    """
    å–å¾— TWSE å…¨å¸‚å ´æ—¥è³‡æ–™ã€‚
    é€™æ”¯ openapi å¯èƒ½ä¸æ”¯æ´ date åƒæ•¸ï¼›è‹¥ä¸æ”¯æ´ï¼Œä»æœƒå›å‚³ã€Œæœ€æ–°ã€ã€‚
    æˆ‘å€‘æ¡ç”¨ï¼šè‹¥ date åƒæ•¸ç„¡æ•ˆï¼Œå›è£œå¯èƒ½æœƒå–åˆ°ç›¸åŒè³‡æ–™ -> ä½†ä»å¯å…ˆè®“ MA è·‘èµ·ä¾†ï¼ˆMVPï¼‰ã€‚
    """
    try:
        url = TWSE_DAILY_ALL
        if for_date is not None:
            ymd = for_date.strftime("%Y%m%d")
            # è‹¥ API ä¸åƒ dateï¼Œä¹Ÿä¸æœƒå£ï¼Œåªæ˜¯å›å‚³æœ€æ–°
            url = f"{TWSE_DAILY_ALL}?date={ymd}"

        status, ct, text = _http_get(url)
        if status != 200:
            return FetchResult(pd.DataFrame(), "TWSE", False, f"HTTP {status} from TWSE")

        ok, data, jerr = _try_parse_json(text)
        if not ok or data is None:
            return FetchResult(pd.DataFrame(), "TWSE", False, f"TWSE JSON parse failed: {jerr}")

        raw = pd.DataFrame(data)
        df = normalize_twse(raw)

        # normalize å¤±æ•—ï¼šæŠŠæ¬„ä½æ¸…å–®å¸¶å‡ºä¾†
        if not {"code", "close"}.issubset(set(df.columns)):
            return FetchResult(
                raw,
                "TWSE",
                False,
                f"TWSE normalize failed; columns={list(raw.columns)[:30]}",
            )

        return FetchResult(df, "TWSE", True)

    except Exception as e:
        return FetchResult(pd.DataFrame(), "TWSE", False, f"{type(e).__name__}: {e}")


# =========================================
# History / Backfill
# =========================================
def append_day(history: pd.DataFrame, day_df: pd.DataFrame, day: pd.Timestamp) -> pd.DataFrame:
    """
    æŠŠç•¶æ—¥è³‡æ–™ append é€² historyï¼Œä¸¦å¼·åˆ¶æ¬„ä½é½Šå…¨ï¼šdate/code/name/close/volume/market
    """
    if day_df is None or len(day_df) == 0:
        return history

    df = day_df.copy()

    # å®¹éŒ¯ï¼šç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
    for col in ["code", "name", "close"]:
        if col not in df.columns:
            # ä»£è¡¨ normalize æ²’æˆåŠŸæˆ–ä½ å‚³é€²ä¾†ä¸æ˜¯ normalize å¾Œè³‡æ–™
            return history

    if "volume" not in df.columns:
        df["volume"] = np.nan
    if "market" not in df.columns:
        df["market"] = "TWSE"

    df["date"] = day
    df["code"] = df["code"].astype(str).str.strip()
    df["name"] = df["name"].astype(str)

    keep = ["date", "code", "name", "close", "volume", "market"]
    df = df[keep].copy()

    out = pd.concat([history, df], ignore_index=True)

    # å»é‡ï¼šåŒä¸€æ—¥åŒä¸€ code åªç•™ä¸€ç­†
    out["date"] = pd.to_datetime(out["date"])
    out = out.drop_duplicates(subset=["date", "code"], keep="last").reset_index(drop=True)
    return out


def backfill_twse_recent_days(history: pd.DataFrame, today: pd.Timestamp, days: int) -> Tuple[pd.DataFrame, List[str]]:
    """
    å¾€å‰è£œ days å€‹ã€Œæ—¥æ›†æ—¥ã€å˜—è©¦æŠ“è³‡æ–™ï¼š
    - é€±æœ«è·³é
    - æŠ“ä¸åˆ°å°±ç•¥é
    """
    errors: List[str] = []
    out = history.copy()

    candidates = _iter_prev_days(today.date(), days)
    for d in reversed(candidates):
        if _is_weekend(d):
            continue

        ts = pd.Timestamp(d)
        r = fetch_twse_daily_all(ts)
        if not r.ok:
            errors.append(f"TWSE {d} fetch failed: {r.error}")
            continue

        # å¦‚æœ API ä¸åƒ dateï¼Œæœƒä¸€ç›´å›æœ€æ–° -> ä» appendï¼Œä½†æœƒå›  date ä¸åŒè€Œå½¢æˆå‡æ­·å²
        # MVP éšæ®µå…ˆæ¥å—ï¼Œä¹‹å¾Œå†æ”¹æˆçœŸæ­£æ­·å²ä¾†æºï¼ˆä¾‹å¦‚ TWSE CSV èˆŠè³‡æ–™æˆ–å…¶ä»– providerï¼‰
        out = append_day(out, r.df, ts)

    return out, errors


def load_history() -> pd.DataFrame:
    if os.path.exists(HISTORY_CSV):
        try:
            df = pd.read_csv(HISTORY_CSV)
            df["date"] = pd.to_datetime(df["date"])
            return df
        except Exception:
            return pd.DataFrame(columns=["date", "code", "name", "close", "volume", "market"])
    return pd.DataFrame(columns=["date", "code", "name", "close", "volume", "market"])


def save_history(df: pd.DataFrame) -> None:
    os.makedirs(OUTPUTS_DIR, exist_ok=True)
    df2 = df.copy()
    df2["date"] = pd.to_datetime(df2["date"]).dt.strftime("%Y-%m-%d")
    df2.to_csv(HISTORY_CSV, index=False, encoding="utf-8")


# =========================================
# Layering (MVP)
# =========================================
def compute_mas(history: pd.DataFrame) -> pd.DataFrame:
    """
    ä»¥æ¯æª”è‚¡ç¥¨çš„ close è¨ˆç®— MA5/10/20ã€‚
    """
    df = history.copy()
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values(["code", "date"]).reset_index(drop=True)

    for w in [5, 10, 20]:
        df[f"ma{w}"] = df.groupby("code")["close"].transform(lambda s: s.rolling(w).mean())

    return df


def layer_today(history_ma: pd.DataFrame, today: pd.Timestamp) -> Tuple[dict, dict]:
    """
    åªç”¨ MA5/10/20 åš MVP åˆ†å±¤ï¼š
      - WARMUPï¼šma20 ä¸è¶³ï¼ˆä¸ç®— Zï¼‰
      - Eï¼šclose > ma5 > ma10 > ma20
      - Bï¼šclose > ma5 > ma10 ä¸” close >= ma20
      - Cï¼šclose > ma10 ä¸” close >= ma20
      - Dï¼šclose > ma20
      - Zï¼šå…¶é¤˜
    """
    df = history_ma.copy()
    df["date"] = pd.to_datetime(df["date"])
    day_df = df[df["date"] == today].copy()

    if len(day_df) == 0:
        return {}, {"summary": "ä»Šæ—¥ç„¡è³‡æ–™ï¼ˆå¯èƒ½æ˜¯ API ç•¶å¤©æœªæ›´æ–°æˆ–å›è£œæ²’æˆåŠŸï¼‰"}

    # æœ€æ–°ä¸€å¤©æ¯è‚¡ä¸€ç­†
    day_df = day_df.sort_values(["code"]).drop_duplicates(subset=["code"], keep="last")

    # warmup
    warmup = day_df[day_df["ma20"].isna()].copy()
    ready = day_df[day_df["ma20"].notna()].copy()

    def _mk_list(x: pd.DataFrame) -> List[dict]:
        x = x.copy()
        x["name"] = x["name"].fillna("")
        return x[["code", "name", "close", "ma5", "ma10", "ma20"]].to_dict(orient="records")

    # ä¿®æ­£ï¼šä½¿ç”¨å®‰å…¨çš„æ¯”è¼ƒæ–¹å¼
    E = ready[
        (ready["close"] > ready["ma5"]) &
        (ready["ma5"] > ready["ma10"]) &
        (ready["ma10"] > ready["ma20"])
    ].copy()

    B = ready[
        (ready["close"] > ready["ma5"]) &
        (ready["ma5"] > ready["ma10"]) &
        (ready["close"] >= ready["ma20"]) &
        (~ready["code"].isin(E["code"]))
    ].copy()

    C = ready[
        (ready["close"] > ready["ma10"]) &
        (ready["close"] >= ready["ma20"]) &
        (~ready["code"].isin(E["code"])) &
        (~ready["code"].isin(B["code"]))
    ].copy()

    D = ready[
        (ready["close"] > ready["ma20"]) &
        (~ready["code"].isin(E["code"])) &
        (~ready["code"].isin(B["code"])) &
        (~ready["code"].isin(C["code"]))
    ].copy()

    Z = ready[
        (~ready["code"].isin(E["code"])) &
        (~ready["code"].isin(B["code"])) &
        (~ready["code"].isin(C["code"])) &
        (~ready["code"].isin(D["code"]))
    ].copy()

    layers = {
        "WARMUP": _mk_list(warmup),
        "E": _mk_list(E),
        "B": _mk_list(B),
        "C": _mk_list(C),
        "D": _mk_list(D),
        "Z": _mk_list(Z),
    }

    meta = {
        "summary": f"åˆ†ä½ˆï¼šWARMUP {len(warmup)} / E {len(E)} / B {len(B)} / C {len(C)} / D {len(D)} / Z {len(Z)}"
    }
    return layers, meta


# =========================================
# HTML
# =========================================
def _fmt_row(r: dict) -> str:
    code = r.get("code", "")
    name = r.get("name", "")
    close = r.get("close", np.nan)
    ma5 = r.get("ma5", np.nan)
    ma10 = r.get("ma10", np.nan)
    ma20 = r.get("ma20", np.nan)

    def f(x):
        return "" if pd.isna(x) else f"{float(x):.2f}"

    title = f"{name} ({code})" if name else f"{code}"
    return (
        f"<tr>"
        f"<td>{title}</td>"
        f"<td style='text-align:right'>{f(close)}</td>"
        f"<td style='text-align:right'>{f(ma5)}</td>"
        f"<td style='text-align:right'>{f(ma10)}</td>"
        f"<td style='text-align:right'>{f(ma20)}</td>"
        f"</tr>"
    )


def render_html(report_date: dt.date, errors: List[str], layers: dict, meta: dict) -> str:
    err_html = ""
    if errors:
        items = "".join([f"<li>{e}</li>" for e in errors[:20]])
        more = ""
        if len(errors) > 20:
            more = f"<div style='margin-top:6px;color:#666'>ï¼ˆå…¶é¤˜ {len(errors)-20} ç­†ç•¥ï¼‰</div>"
        err_html = f"""
        <h2>å³æ™‚è­¦ç¤ºï¼ˆæ‘˜è¦ï½œMVPï¼‰</h2>
        <ul>{items}</ul>
        {more}
        """
    else:
        err_html = f"""
        <h2>å³æ™‚è­¦ç¤ºï¼ˆæ‘˜è¦ï½œMVPï¼‰</h2>
        <ul>
          <li>ğŸŸ¢ ç›®å‰åªè·‘ TWSEï¼ˆTPEx æš«åœï¼‰</li>
          <li>ğŸŸ¢ {meta.get("summary","")}</li>
        </ul>
        """

    def section(title: str, key: str) -> str:
        rows = layers.get(key, [])
        if not rows:
            body = "<div>(ç©º)</div>"
        else:
            trs = "\n".join(_fmt_row(r) for r in rows[:200])
            if len(rows) > 200:
                tail = f"<div style='margin-top:8px;color:#666'>ï¼ˆåƒ…é¡¯ç¤ºå‰ 200 ç­†ï¼›å¯¦éš› {len(rows)} ç­†ï¼‰</div>"
            else:
                tail = ""
            body = f"""
            <table>
              <thead>
                <tr>
                  <th style="text-align:left">åç¨± (ä»£è™Ÿ)</th>
                  <th style="text-align:right">æ”¶ç›¤</th>
                  <th style="text-align:right">MA5</th>
                  <th style="text-align:right">MA10</th>
                  <th style="text-align:right">MA20</th>
                </tr>
              </thead>
              <tbody>
                {trs}
              </tbody>
            </table>
            {tail}
            """
        return f"<h2>{title}</h2>{body}"

    html = f"""
<!doctype html>
<html lang="zh-Hant">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>æ¯æ—¥åˆ†å±¤å ±è¡¨</title>
  <style>
    body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Noto Sans TC", "PingFang TC", "Microsoft JhengHei", Arial, sans-serif; margin: 28px; color:#111; }}
    h1 {{ font-size: 44px; margin: 0 0 10px 0; }}
    .date {{ font-size: 18px; color:#333; margin-bottom: 18px; }}
    h2 {{ font-size: 28px; margin-top: 30px; }}
    ul {{ line-height: 1.6; }}
    table {{ border-collapse: collapse; width: 100%; margin-top: 10px; }}
    th, td {{ border-bottom: 1px solid #eee; padding: 10px 8px; }}
    th {{ background: #fafafa; }}
    .note {{ margin-top: 26px; color:#666; border-top: 1px solid #eee; padding-top: 12px; }}
  </style>
</head>
<body>
  <h1>æ¯æ—¥åˆ†å±¤å ±è¡¨</h1>
  <div class="date">æ—¥æœŸï¼š{report_date}ï¼ˆ{TZ}ï¼‰</div>

  {err_html}

  {section("WARMUPï¼ˆè³‡æ–™ä¸è¶³ï¼Œä¸ç®— Zï¼‰", "WARMUP")}
  {section("E å±¤", "E")}
  {section("B å±¤", "B")}
  {section("C å±¤", "C")}
  {section("D å±¤", "D")}
  {section("Z å±¤", "Z")}

  <div class="note">
    è¨»ï¼šåˆç‰ˆå…ˆä»¥ TWSE + MA5/10/20 è®“åˆ†å±¤ã€Œå¯ç”¨å¯çœ‹ã€ã€‚å¾ŒçºŒå†åŠ å…¥ TPExã€MA60/240ã€RSã€ç‡Ÿæ”¶èˆ‡è¦å‰‡å…¨æ–‡ã€‚
  </div>
</body>
</html>
"""
    return html


# =========================================
# Main
# =========================================
def main() -> int:
    os.makedirs(OUTPUTS_DIR, exist_ok=True)
    os.makedirs(DOCS_DIR, exist_ok=True)

    # ä»¥å°åŒ—æ—¥æœŸç‚ºæº–
    report_date = _now_taipei_date()
    today = pd.Timestamp(report_date)

    errors: List[str] = []

    # è®€èˆŠæ­·å²
    hist = load_history()

    # å…ˆæŠ“ã€Œä»Šæ—¥ã€ï¼ˆæˆ–æœ€æ–°ï¼‰è³‡æ–™
    r_today = fetch_twse_daily_all(today)
    if not r_today.ok:
        errors.append(f"TWSE ä»Šæ—¥å–å¾—å¤±æ•—ï¼š{r_today.error}")
    else:
        hist = append_day(hist, r_today.df, today)

    # å›è£œ
    hist, backfill_errors = backfill_twse_recent_days(hist, today, BACKFILL_DAYS)
    # backfill_errors å¤ªå¤šæœƒåˆ·ç‰ˆï¼Œå…ˆæ”¾æ‘˜è¦
    if backfill_errors:
        errors.append(f"TWSE å›è£œï¼šå¤±æ•— {len(backfill_errors)} æ¬¡ï¼ˆMVP å…ˆå¿½ç•¥ç´°ç¯€ï¼‰")

    # ç®— MA
    hist_ma = compute_mas(hist)

    # åˆ†å±¤
    layers, meta = layer_today(hist_ma, today)

    # å­˜æ­·å²
    save_history(hist)

    # ç”¢ HTMLï¼ˆåŒæ™‚å¯« outputs/ èˆ‡ docs/ï¼‰
    html = render_html(report_date, errors, layers, meta)

    with open(HTML_PATH_OUTPUTS, "w", encoding="utf-8") as f:
        f.write(html)
    with open(HTML_PATH_DOCS, "w", encoding="utf-8") as f:
        f.write(html)

    print("OK: wrote reports to outputs/index.html and docs/index.html")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
