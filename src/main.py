from __future__ import annotations

import os
import json
import datetime as dt
from dataclasses import dataclass
from typing import Optional, Tuple, Any, List, Dict

import numpy as np
import pandas as pd
import requests

# =========================================
# Configï¼ˆä½ åªéœ€è¦æ”¹é€™è£¡ï¼‰
# =========================================
TZ = "Asia/Taipei"

# å¾€å‰è£œã€Œäº¤æ˜“æ—¥ã€(ä¸æ˜¯æ—¥æ›†æ—¥)
# å»ºè­°è‡³å°‘ 30ï¼šç¢ºä¿ MA20 æˆç«‹ã€é‚„æœ‰äº›ç·©è¡
BACKFILL_TRADING_DAYS = 35

# MA è¦–çª—ï¼ˆå…ˆåš MVPï¼‰
MA_WINDOWS = [5, 10, 20]

# åªåš TWSEï¼ˆTPEx å…ˆä¸è™•ç†ï¼‰
# é€™å€‹æ˜¯ã€ŒèˆŠç«™ JSONã€ï¼Œdate çœŸçš„æœ‰æ•ˆï¼Œèƒ½æ‹¿æ­·å²
TWSE_MI_INDEX = "https://www.twse.com.tw/exchangeReport/MI_INDEX"

OUTPUTS_DIR = "outputs"
DOCS_DIR = "docs"
HISTORY_CSV = os.path.join(OUTPUTS_DIR, "history_prices.csv")
HTML_PATH_OUTPUTS = os.path.join(OUTPUTS_DIR, "index.html")
HTML_PATH_DOCS = os.path.join(DOCS_DIR, "index.html")


# =========================================
# Data Structures
# =========================================
@dataclass
class FetchResult:
    df: pd.DataFrame
    source: str
    ok: bool
    error: Optional[str] = None


# =========================================
# Time / Helpers
# =========================================
def _now_taipei_date() -> dt.date:
    # GitHub runner å¤šåŠæ˜¯ UTC
    now_utc = dt.datetime.utcnow()
    now_tw = now_utc + dt.timedelta(hours=8)
    return now_tw.date()


def _is_weekend(d: dt.date) -> bool:
    return d.weekday() >= 5  # Sat/Sun


def _http_get_json(url: str, params: Dict[str, str], timeout: int = 30) -> Tuple[bool, Any, str]:
    headers = {
        "User-Agent": "Mozilla/5.0 (GitHub Actions; tw-stock-layers)",
        "Accept": "application/json,text/plain,*/*",
        "Referer": "https://www.twse.com.tw/",
    }
    r = requests.get(url, headers=headers, params=params, timeout=timeout)
    if r.status_code != 200:
        return False, None, f"HTTP {r.status_code}"
    try:
        return True, r.json(), ""
    except Exception as e:
        return False, None, f"JSONDecodeError: {e}"


def _to_float(x: Any) -> float:
    if x is None:
        return np.nan
    s = str(x).strip().replace(",", "")
    if s in ("", "--", "nan", "None"):
        return np.nan
    try:
        return float(s)
    except Exception:
        return np.nan


def _pick_index(fields: List[str], candidates: List[str]) -> Optional[int]:
    # å…ˆå®Œå…¨åŒ¹é…
    for c in candidates:
        if c in fields:
            return fields.index(c)
    # å†åšå¤§å°å¯«/ç©ºç™½å¯¬é¬†
    norm = {str(f).strip().lower(): i for i, f in enumerate(fields)}
    for c in candidates:
        k = str(c).strip().lower()
        if k in norm:
            return norm[k]
    return None


# =========================================
# Fetch (TWSE MI_INDEX by date)
# =========================================
def fetch_twse_day_all(day: dt.date) -> FetchResult:
    """
    ç”¨ TWSE MI_INDEX æŠ“ã€ŒæŒ‡å®šæ—¥æœŸã€çš„æ•´å¸‚å ´è³‡æ–™ï¼ˆçœŸæ­£æ­·å²ï¼‰ã€‚
    """
    ymd = day.strftime("%Y%m%d")
    params = {
        "response": "json",
        "date": ymd,
        "type": "ALL",  # ALL / ALLBUT0999 ç­‰ï¼›å…ˆç”¨ ALL
    }

    ok, data, err = _http_get_json(TWSE_MI_INDEX, params=params)
    if not ok:
        return FetchResult(pd.DataFrame(), "TWSE", False, f"TWSE MI_INDEX {ymd} fetch failed: {err}")

    # å¸¸è¦‹ï¼šä¼‘å¸‚æœƒå›å‚³ stat != OK
    stat = str(data.get("stat", "")).upper()
    if stat != "OK":
        return FetchResult(pd.DataFrame(), "TWSE", False, f"TWSE MI_INDEX {ymd} stat={data.get('stat')}")

    fields = data.get("fields", [])
    rows = data.get("data", [])
    if not fields or not rows:
        return FetchResult(pd.DataFrame(), "TWSE", False, f"TWSE MI_INDEX {ymd} empty fields/data")

    # å¿…è¦æ¬„ä½ï¼ˆæœƒå› ç‰ˆæœ¬ç•¥ä¸åŒï¼Œæ‰€ä»¥å¤šæ”¾å¹¾å€‹å€™é¸ï¼‰
    i_code = _pick_index(fields, ["è­‰åˆ¸ä»£è™Ÿ", "è‚¡ç¥¨ä»£è™Ÿ", "Code"])
    i_name = _pick_index(fields, ["è­‰åˆ¸åç¨±", "è‚¡ç¥¨åç¨±", "Name"])
    i_close = _pick_index(fields, ["æ”¶ç›¤åƒ¹", "æ”¶ç›¤", "ClosingPrice", "close"])
    i_vol = _pick_index(fields, ["æˆäº¤è‚¡æ•¸", "æˆäº¤é‡", "TradeVolume", "volume"])

    if i_code is None or i_close is None:
        return FetchResult(
            pd.DataFrame(),
            "TWSE",
            False,
            f"TWSE MI_INDEX {ymd} missing required fields; fields_sample={fields[:20]}",
        )

    out = []
    for r in rows:
        # rows é€šå¸¸æ˜¯ list[str]
        code = str(r[i_code]).strip() if i_code < len(r) else ""
        if not code:
            continue
        name = str(r[i_name]).strip() if (i_name is not None and i_name < len(r)) else ""
        close = _to_float(r[i_close]) if i_close < len(r) else np.nan
        if pd.isna(close):
            continue
        vol = _to_float(r[i_vol]) if (i_vol is not None and i_vol < len(r)) else np.nan
        out.append((code, name, close, vol))

    df = pd.DataFrame(out, columns=["code", "name", "close", "volume"])
    df["market"] = "TWSE"
    df["date"] = pd.Timestamp(day)
    df = df.drop_duplicates(subset=["date", "code"], keep="last").reset_index(drop=True)

    return FetchResult(df, "TWSE", True)


# =========================================
# History I/O
# =========================================
def load_history() -> pd.DataFrame:
    if os.path.exists(HISTORY_CSV):
        try:
            df = pd.read_csv(HISTORY_CSV)
            df["date"] = pd.to_datetime(df["date"])
            return df
        except Exception:
            pass
    return pd.DataFrame(columns=["date", "code", "name", "close", "volume", "market"])


def save_history(df: pd.DataFrame) -> None:
    os.makedirs(OUTPUTS_DIR, exist_ok=True)
    df2 = df.copy()
    df2["date"] = pd.to_datetime(df2["date"]).dt.strftime("%Y-%m-%d")
    df2.to_csv(HISTORY_CSV, index=False, encoding="utf-8")


def merge_day(history: pd.DataFrame, day_df: pd.DataFrame) -> pd.DataFrame:
    if day_df is None or day_df.empty:
        return history
    keep = ["date", "code", "name", "close", "volume", "market"]
    df = day_df.copy()
    for c in keep:
        if c not in df.columns:
            return history
    out = pd.concat([history, df[keep]], ignore_index=True)
    out["date"] = pd.to_datetime(out["date"])
    out["code"] = out["code"].astype(str).str.strip()
    out = out.drop_duplicates(subset=["date", "code"], keep="last").reset_index(drop=True)
    return out


def backfill_trading_days(history: pd.DataFrame, end_day: dt.date, n_trading_days: int) -> Tuple[pd.DataFrame, List[str]]:
    """
    å¾ end_day å¾€å‰å›è£œã€ŒæˆåŠŸæŠ“åˆ°çš„äº¤æ˜“æ—¥ã€é” n_trading_daysã€‚
    - é€±æœ«è·³é
    - ä¼‘å¸‚/æŠ“ä¸åˆ°ï¼šç•¥éä½†è¨˜éŒ„
    """
    errors: List[str] = []
    out = history.copy()

    got = 0
    cur = end_day
    max_lookback = n_trading_days * 3  # ç·©è¡ï¼šé¿å…é€£å‡/éŒ¯èª¤å°è‡´æ‰¾å¤ªä¹…
    tried = 0

    while got < n_trading_days and tried < max_lookback:
        tried += 1
        cur = cur - dt.timedelta(days=1)
        if _is_weekend(cur):
            continue

        r = fetch_twse_day_all(cur)
        if not r.ok:
            errors.append(r.error or f"TWSE {cur} failed")
            continue

        out = merge_day(out, r.df)
        got += 1

    return out, errors


# =========================================
# Indicators / Layering (MVP)
# =========================================
def compute_mas(history: pd.DataFrame) -> pd.DataFrame:
    df = history.copy()
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values(["code", "date"]).reset_index(drop=True)

    for w in MA_WINDOWS:
        df[f"ma{w}"] = df.groupby("code")["close"].transform(lambda s: s.rolling(w).mean())

    return df


def layer_today(history_ma: pd.DataFrame, today: pd.Timestamp) -> Tuple[dict, dict]:
    """
    åªç”¨ MA5/10/20 åš MVP åˆ†å±¤ï¼ˆä½ å…ˆè¦ã€Œçœ‹åˆ°çœŸçš„è³‡æ–™ã€ï¼‰
      - WARMUPï¼šma20 ä¸è¶³ï¼ˆä¸ç®— Zï¼‰
      - Eï¼šclose > ma5 > ma10 > ma20
      - Bï¼šclose > ma5 > ma10 ä¸” close >= ma20
      - Cï¼šclose > ma10 ä¸” close >= ma20
      - Dï¼šclose > ma20
      - Zï¼šå…¶é¤˜
    """
    df = history_ma.copy()
    df["date"] = pd.to_datetime(df["date"])
    day_df = df[df["date"] == today].copy()

    if day_df.empty:
        return {}, {"summary": "ä»Šæ—¥ç„¡è³‡æ–™ï¼ˆå¯èƒ½æ˜¯äº¤æ˜“æ‰€å°šæœªæ›´æ–°æˆ–ä»Šå¤©éäº¤æ˜“æ—¥ï¼‰"}

    day_df = day_df.sort_values(["code"]).drop_duplicates(subset=["code"], keep="last")

    # ä»¥ ma20 ä½œç‚ºã€Œæ˜¯å¦å¯åˆ†å±¤ã€çš„é–€æª»
    warmup = day_df[day_df["ma20"].isna()].copy()
    ready = day_df[day_df["ma20"].notna()].copy()

    def _mk_list(x: pd.DataFrame) -> List[dict]:
        x = x.copy()
        x["name"] = x["name"].fillna("")
        cols = ["code", "name", "close", "ma5", "ma10", "ma20"]
        for c in cols:
            if c not in x.columns:
                x[c] = np.nan
        return x[cols].to_dict(orient="records")

    E = ready[(ready["close"] > ready["ma5"]) & (ready["ma5"] > ready["ma10"]) & (ready["ma10"] > ready["ma20"])].copy()
    B = ready[(ready["close"] > ready["ma5"]) & (ready["ma5"] > ready["ma10"]) & (ready["close"] >= ready["ma20"]) & (~ready["code"].isin(E["code"]))].copy()
    C = ready[(ready["close"] > ready["ma10"]) & (ready["close"] >= ready["ma20"]) & (~ready["code"].isin(E["code"])) & (~ready["code"].isin(B["code"]))].copy()
    D = ready[(ready["close"] > ready["ma20"]) & (~ready["code"].isin(E["code"])) & (~ready["code"].isin(B["code"])) & (~ready["code"].isin(C["code"]))].copy()
    Z = ready[(~ready["code"].isin(E["code"])) & (~ready["code"].isin(B["code"])) & (~ready["code"].isin(C["code"])) & (~ready["code"].isin(D["code"]))].copy()

    layers = {
        "WARMUP": _mk_list(warmup),
        "E": _mk_list(E),
        "B": _mk_list(B),
        "C": _mk_list(C),
        "D": _mk_list(D),
        "Z": _mk_list(Z),
    }

    meta = {"summary": f"åˆ†ä½ˆï¼šWARMUP {len(warmup)} / E {len(E)} / B {len(B)} / C {len(C)} / D {len(D)} / Z {len(Z)}"}
    return layers, meta


# =========================================
# HTML
# =========================================
def _fmt_row(r: dict) -> str:
    code = r.get("code", "")
    name = r.get("name", "")
    close = r.get("close", np.nan)
    ma5 = r.get("ma5", np.nan)
    ma10 = r.get("ma10", np.nan)
    ma20 = r.get("ma20", np.nan)

    def f(x):
        return "" if pd.isna(x) else f"{float(x):.2f}"

    title = f"{name} ({code})" if name else f"{code}"
    return (
        f"<tr>"
        f"<td>{title}</td>"
        f"<td style='text-align:right'>{f(close)}</td>"
        f"<td style='text-align:right'>{f(ma5)}</td>"
        f"<td style='text-align:right'>{f(ma10)}</td>"
        f"<td style='text-align:right'>{f(ma20)}</td>"
        f"</tr>"
    )


def render_html(report_date: dt.date, errors: List[str], layers: dict, meta: dict) -> str:
    if errors:
        items = "".join([f"<li>{e}</li>" for e in errors[:12]])
        more = f"<div style='margin-top:6px;color:#666'>ï¼ˆå…¶é¤˜ {max(0,len(errors)-12)} ç­†ç•¥ï¼‰</div>" if len(errors) > 12 else ""
        alert = f"<h2>å³æ™‚è­¦ç¤ºï¼ˆæ‘˜è¦ï½œMVPï¼‰</h2><ul>{items}</ul>{more}"
    else:
        alert = f"<h2>å³æ™‚è­¦ç¤ºï¼ˆæ‘˜è¦ï½œMVPï¼‰</h2><ul><li>ğŸŸ¢ ç›®å‰åªè·‘ TWSEï¼ˆTPEx æš«åœï¼‰</li><li>ğŸŸ¢ {meta.get('summary','')}</li></ul>"

    def section(title: str, key: str) -> str:
        rows = layers.get(key, [])
        if not rows:
            return f"<h2>{title}</h2><div>(ç©º)</div>"
        trs = "\n".join(_fmt_row(r) for r in rows[:200])
        tail = f"<div style='margin-top:8px;color:#666'>ï¼ˆåƒ…é¡¯ç¤ºå‰ 200 ç­†ï¼›å¯¦éš› {len(rows)} ç­†ï¼‰</div>" if len(rows) > 200 else ""
        return f"""
        <h2>{title}</h2>
        <table>
          <thead>
            <tr>
              <th style="text-align:left">åç¨± (ä»£è™Ÿ)</th>
              <th style="text-align:right">æ”¶ç›¤</th>
              <th style="text-align:right">MA5</th>
              <th style="text-align:right">MA10</th>
              <th style="text-align:right">MA20</th>
            </tr>
          </thead>
          <tbody>
            {trs}
          </tbody>
        </table>
        {tail}
        """

    return f"""<!doctype html>
<html lang="zh-Hant">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>æ¯æ—¥åˆ†å±¤å ±è¡¨</title>
  <style>
    body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Noto Sans TC", "PingFang TC", "Microsoft JhengHei", Arial, sans-serif; margin: 28px; color:#111; }}
    h1 {{ font-size: 44px; margin: 0 0 10px 0; }}
    .date {{ font-size: 18px; color:#333; margin-bottom: 18px; }}
    h2 {{ font-size: 28px; margin-top: 30px; }}
    ul {{ line-height: 1.6; }}
    table {{ border-collapse: collapse; width: 100%; margin-top: 10px; }}
    th, td {{ border-bottom: 1px solid #eee; padding: 10px 8px; }}
    th {{ background: #fafafa; }}
    .note {{ margin-top: 26px; color:#666; border-top: 1px solid #eee; padding-top: 12px; }}
  </style>
</head>
<body>
  <h1>æ¯æ—¥åˆ†å±¤å ±è¡¨</h1>
  <div class="date">æ—¥æœŸï¼š{report_date}ï¼ˆ{TZ}ï¼‰</div>
  {alert}
  {section("WARMUPï¼ˆè³‡æ–™ä¸è¶³ï¼Œä¸ç®— Zï¼‰", "WARMUP")}
  {section("E å±¤", "E")}
  {section("B å±¤", "B")}
  {section("C å±¤", "C")}
  {section("D å±¤", "D")}
  {section("Z å±¤", "Z")}
  <div class="note">
    è¨»ï¼šæœ¬ç‰ˆæ”¹ç”¨ TWSE MI_INDEXï¼ˆå¯æŠ“æŒ‡å®šæ—¥æœŸï¼‰å»ºç«‹ã€ŒçœŸæ­·å²ã€ï¼ŒMA5/10/20 æ‰æœ‰æ„ç¾©ã€‚ä¸‹ä¸€æ­¥å†åŠ  TPEx èˆ‡ä½ çš„ v7.9.9.x è¦å‰‡å…¨æ–‡ã€‚
  </div>
</body>
</html>
"""


# =========================================
# Main
# =========================================
def main() -> int:
    os.makedirs(OUTPUTS_DIR, exist_ok=True)
    os.makedirs(DOCS_DIR, exist_ok=True)

    report_date = _now_taipei_date()
    today = pd.Timestamp(report_date)

    errors: List[str] = []

    hist = load_history()

    # å…ˆæŠ“ã€Œä»Šå¤©ã€ï¼ˆè‹¥éäº¤æ˜“æ—¥å¯èƒ½å¤±æ•—ï¼Œä»å¯ç”¨å›è£œçš„æœ€è¿‘äº¤æ˜“æ—¥ï¼‰
    r_today = fetch_twse_day_all(report_date)
    if r_today.ok:
        hist = merge_day(hist, r_today.df)
    else:
        errors.append(f"TWSE ä»Šæ—¥å–å¾—å¤±æ•—ï¼š{r_today.error}")

    # å›è£œï¼šè£œè¶³äº¤æ˜“æ—¥æ•¸
    hist, backfill_errors = backfill_trading_days(hist, report_date, BACKFILL_TRADING_DAYS)
    if backfill_errors:
:
        # ä¸è¦åˆ·ç‰ˆï¼šåªæ‘˜è¦
        errors.append(f"TWSE å›è£œå¤±æ•— {len(backfill_errors)} æ¬¡ï¼ˆå¸¸è¦‹åŸå› ï¼šä¼‘å¸‚/é€£å‡/äº¤æ˜“æ‰€æš«æ™‚æ“‹ï¼‰")

    # ç®— MA
    hist_ma = compute_mas(hist)

    # åˆ†å±¤ï¼šå¦‚æœä»Šå¤©æ²’è³‡æ–™ï¼Œæœƒé¡¯ç¤ºã€Œä»Šæ—¥ç„¡è³‡æ–™ã€
    layers, meta = layer_today(hist_ma, today)

    save_history(hist)

    html = render_html(report_date, errors, layers, meta)
    with open(HTML_PATH_OUTPUTS, "w", encoding="utf-8") as f:
        f.write(html)
    with open(HTML_PATH_DOCS, "w", encoding="utf-8") as f:
        f.write(html)

    print("OK: wrote reports to outputs/index.html and docs/index.html")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
